{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#네이버 생활/문화카테고리의 생활/문화 일반부분 뉴스기사\n",
    "def get_url(page):\n",
    "    url = 'https://news.naver.com/main/list.nhn?mode=LS2D&mid=shm&sid2=245&sid1=103&date=20190122&page='\n",
    "    url += str(page)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    crawl_ls = soup.select('div[class=\"list_body newsflash_body\"] ul[class=\"type06_headline\"] li dl')    # 처음 10개 기사\n",
    "    crawl_ls += soup.select('div[class=\"list_body newsflash_body\"] ul[class=\"type06\"] li dl')    # 다음 10개 기사\n",
    "    \n",
    "    url_ls = []\n",
    "    for url in crawl_ls:\n",
    "        url_ls += url.select('dt:nth-of-type(1) a')    # url태그가 여러개이므로 1번째 dt태그 지정\n",
    "    \n",
    "    return url_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기사 내용 크롤링\n",
    "def get_content(num, url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    for match in soup.findAll('script'):\n",
    "        match.replace_with('')\n",
    "        \n",
    "    content_ls = soup.select('div[id=\"articleBodyContents\"]')\n",
    "        \n",
    "    for content in content_ls:\n",
    "        f.write('\"{0}\" ,\"{1}\" \\n'.format(num, content.get_text().strip()))\n",
    "        num += 1\n",
    "    \n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "f = open('culture_news.txt','w',encoding='utf-8')\n",
    "\n",
    "# 5페이지까지 크롤링\n",
    "for page in [1,2,3,4,5]:\n",
    "    url_ls = get_url(page)\n",
    "    for url in url_ls:\n",
    "        num = get_content(num,url['href'])\n",
    "        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 읽기\n",
    "# f = open('./IT_news','r',encoding='utf-8')\n",
    "# line = f.read() \n",
    "# f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
